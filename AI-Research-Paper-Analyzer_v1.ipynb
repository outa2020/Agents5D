{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6eb1b1",
   "metadata": {},
   "source": [
    "# ðŸ¤– Automated Research Paper Analysis System\n",
    "**Multi-Agent AI System for Academic Research Analysis**\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Mohamed Outahajala  \n",
    " \n",
    "**Framework**: Google Agent Development Kit (ADK)  \n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Upload your PDF research paper as `document.pdf`\n",
    "2. Set your API keys in `.env`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d0fc0",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Analyzing research papers manually is time-consuming and requires:\n",
    "- Reading lengthy PDFs\n",
    "- Summarizing key findings\n",
    "- Researching latest trends\n",
    "- Synthesizing information from multiple sources\n",
    "\n",
    "This process can take 2-3 hours per paper.\n",
    "\n",
    "## Solution\n",
    "An automated Multi-Agent Research System that:\n",
    "- Extracts PDF content automatically\n",
    "- Generates comprehensive summaries\n",
    "- Performs real-time market research\n",
    "- Produces structured reports in under 5 minutes\n",
    "\n",
    "**Value**: Reduces research time by 95%, from 3 hours to 5 minutes per paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ca3ea",
   "metadata": {},
   "source": [
    "<!-- if numpy or pandas .. not installed -->\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install pypdf\n",
    "!pip install google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eea3986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_SEARCH_API_KEY = os.getenv(\"GOOGLE_SEARCH_API_KEY\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gemini-2.5-flash\")  # Default to \"gemini-2.5-flash\" if not set   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e264923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75aac47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config=types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fc24a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9e4b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/admin/HF/Agents5D\n",
      "Files in current directory:\n",
      "  ðŸ“„ document.pdf\n",
      "âœ… 'document.pdf' found and accessible\n",
      "   Pages: 5\n",
      "   First 100 chars: Tagging Amazigh with AnCoraPipe \n",
      "Mohamed Outahajala, Lahbib Zekouar, Paolo Rosso, M. AntÃ²nia MartÃ­ \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check if document.pdf is accessible\n",
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in current directory:\")\n",
    "for item in os.listdir('.'):\n",
    "    if item.endswith('.pdf'):\n",
    "        print(f\"  ðŸ“„ {item}\")\n",
    "\n",
    "# Check if document.pdf exists\n",
    "pdf_path = \"document.pdf\"\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"âœ… '{pdf_path}' found and accessible\")\n",
    "    # Quick test read\n",
    "    from pypdf import PdfReader\n",
    "    reader = PdfReader(pdf_path)\n",
    "    print(f\"   Pages: {len(reader.pages)}\")\n",
    "    print(f\"   First 100 chars: {reader.pages[0].extract_text()[:100]}...\")\n",
    "else:\n",
    "    print(f\"âŒ '{pdf_path}' NOT found in current directory\")\n",
    "    print(f\"   You may need to specify the full path or move the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56e26a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PDF Search Tool initialized.\n",
      "âœ… PDF Reader Agent created.\n"
     ]
    }
   ],
   "source": [
    "# PDF Search Tool\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def search_pdf_tool(file_path: str, query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for keywords within a PDF file and returns relevant text snippets.\n",
    "    If the file is not found, returns mock data for demonstration.\n",
    "    \"\"\"\n",
    "    print(f\"    ðŸ”Ž [Tool] Searching PDF '{file_path}' for: '{query}'\")\n",
    "    \n",
    "    # 1. Try to read the actual file\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            reader = PdfReader(file_path)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "            \n",
    "            # Return full document text instead of keyword matching\n",
    "            if text.strip():\n",
    "                return text[:5000]  # Return first 5000 chars to avoid token limits\n",
    "            else:\n",
    "                return \"PDF file is empty or unreadable.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error reading PDF: {e}\"\n",
    "\n",
    "    # 2. Fallback Mock Data (for testing without a file)\n",
    "    else:\n",
    "        print(f\"    âš ï¸ [Tool] File not found. Using MOCK data for demonstration.\")\n",
    "        mock_content = \"\"\"\n",
    "Research Paper: Advanced AI Systems\n",
    "\n",
    "Abstract: This paper presents a novel framework for multi-agent AI systems that can collaborate to solve complex research problems.\n",
    "\n",
    "Introduction: The field of artificial intelligence has rapidly evolved with the emergence of large language models and agent-based architectures.\n",
    "\n",
    "Methodology: We employed a sequential workflow combining PDF analysis, parallel processing, and result aggregation using the Google ADK framework.\n",
    "\n",
    "Key Findings:\n",
    "- Multi-agent systems show 95% improvement in research analysis speed\n",
    "- Parallel execution reduces processing time by 60%\n",
    "- Integration with real-time search enables up-to-date information retrieval\n",
    "\n",
    "Conclusion: Our approach demonstrates significant improvements in automating research paper analysis.\n",
    "        \"\"\"\n",
    "        return mock_content\n",
    "\n",
    "print(\"âœ… PDF Search Tool initialized.\")\n",
    "\n",
    "# 1. PDF Reader Agent \n",
    "pdf_reader_agent = Agent(\n",
    "    name=\"PDFReader\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an expert document researcher. \n",
    "    Your job is to use the `search_pdf_tool` to extract the full content from document.pdf.\n",
    "    Then analyze it to provide:\n",
    "    1. **Main Topic**: What is the paper about?\n",
    "    2. **Key Contributions**: Novel contributions and innovations\n",
    "    3. **Methodology**: Approaches and methods used\n",
    "    4. **Results/Findings**: Main outcomes and conclusions\n",
    "    \n",
    "    Cite specific sections from the document.\"\"\",\n",
    "    tools=[FunctionTool(search_pdf_tool)],\n",
    "    output_key=\"pdf_findings\"\n",
    ")\n",
    "print(\"âœ… PDF Reader Agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "070ee52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Summarizer Agent\n",
    "summarizer_agent = Agent(\n",
    "    name=\"Summarizer\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an expert scientific paper analyst. \n",
    "    Read the research paper content provided: {pdf_findings}\n",
    "    \n",
    "    Create a comprehensive summary that includes:\n",
    "    1. **Main Topic**: What is the paper about?\n",
    "    2. **Key Contributions**: What are the novel contributions and innovations?\n",
    "    3. **Methodology**: What approaches or methods were used?\n",
    "    4. **Results/Findings**: What were the main outcomes?\n",
    "    \n",
    "    Keep the summary clear, structured, and under 200 words.\n",
    "    If the findings are empty, state that no information was found.\"\"\",\n",
    "    output_key=\"final_summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b288e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tech Researcher\n",
    "tech_researcher = Agent(\n",
    "    name=\"Tech_Researcher\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "\n",
    "    instruction=\"\"\"\n",
    "You are a senior research analyst.\n",
    "\n",
    "Input: {pdf_findings}\n",
    "\n",
    "1. Extract the paperâ€™s **main technical focus**, research problem, and method.\n",
    "2. Evaluate the paper technically:\n",
    "   - What is innovative?\n",
    "   - What is weak or missing?\n",
    "   - What assumptions does it make?\n",
    "   - Possible real-world applications?\n",
    "3. Perform a web search using the search tool:\n",
    "   - Find the latest (2024â€“2025) work, breakthroughs, or criticisms related to the same topic.\n",
    "   - Prefer scholarly or technical sources.\n",
    "4. Produce a concise synthesis (max 100 words):\n",
    "   - Technical evaluation of the paper\n",
    "   - How the latest research trends compare or validate/challenge it\n",
    "   - Missing gaps or future directions\n",
    "\n",
    "Your output must be factual, technical, and short.\n",
    "\"\"\",\n",
    "\n",
    "    tools=[google_search],\n",
    "    output_key=\"tech_research\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1cc92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ParallelAgent runs all its sub-agents simultaneously\n",
    "# other agents can be added here later\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"ParallelResearchTeam\",\n",
    "    sub_agents=[summarizer_agent, tech_researcher],\n",
    ")\n",
    "\n",
    "# Agregate results from parallel agents\n",
    "research_aggregator = Agent(\n",
    "    name=\"ResearchAggregator\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "You are a research synthesis expert.\n",
    "Input:\n",
    "1. Summary from Summarizer Agent: {final_summary}\n",
    "2. Technical research from Tech Researcher Agent: {tech_research}\n",
    "Your task is to combine these inputs into a single, coherent research report that addresses the user's original question. Ensure the report is clear, concise, and well-structured.\n",
    "\"\"\",\n",
    "    output_key=\"research_report\"\n",
    ")\n",
    "\n",
    "# Create the Sequential Agent to agregate read PDF, then run workflow\n",
    "agents = SequentialAgent(\n",
    "    name=\"ResearchWorkflowAgent\",\n",
    "    sub_agents=[pdf_reader_agent, parallel_research_team, research_aggregator],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4e24d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "App name mismatch detected. The runner is configured with app name \"InMemoryRunner\", but the root agent was loaded from \"/Users/admin/HF/Agents5D/.venv/lib/python3.10/site-packages/google/adk/agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Analyse document.pdf the document and provide a comprehensive summary of the key findings and methodology.\n",
      "    ðŸ”Ž [Tool] Searching PDF 'document.pdf' for: ''\n",
      "PDFReader > This paper, \"Tagging Amazigh with AnCoraPipe,\" addresses the scarcity of Natural Language Processing (NLP) tools and resources for the Amazigh language. The authors aim to introduce morphosyntactic tagging for Amazigh, utilizing the AnCora Pipe multilevel annotation tool.\n",
      "\n",
      "**Main Topic**: The primary focus of the paper is to present the features of the Amazigh language for morphology annotation, specifically addressing its tagging with the AnCora Pipe tool. This endeavor is viewed as an initial step towards the automatic processing of the Amazigh language, with the ultimate goal of developing a part-of-speech tagger. (Abstract, Introduction)\n",
      "\n",
      "**Key Contributions**:\n",
      "*   **Addressing Tool Scarcity**: The paper proposes to equip the Amazigh language with an important morphosyntactic tagging tool, acknowledging the significant lack of such resources for non-European languages like Amazigh. (Introduction)\n",
      "*   **AnCoraPipe Adaptation**: It outlines the adaptation of the AnCora Pipe tool to incorporate a specific tagset designed for annotating Amazigh corpora, adhering to a newly defined writing system. (Abstract)\n",
      "*   **Foundation for Automatic Processing**: The work is positioned as the \"first step for an automatic processing of the Amazigh language,\" with the immediate aim of achieving a part-of-speech tagger. (Abstract)\n",
      "\n",
      "**Methodology**:\n",
      "The paper outlines a structured approach to achieve its objectives:\n",
      "*   **Language Features Overview**: Initially, it provides an overview of the Amazigh language's features, noting its Hamito-Semitic/â€œAfro-Asiaticâ€ origins and rich templatic morphology, along with its dialectal proliferation. (The Amazigh language, Introduction)\n",
      "*   **Morphology Retrospective**: A brief retrospective on Amazigh morphology, as conceptualized by IRCAM linguists, is presented. (Introduction)\n",
      "*   **Corpus Overview**: The methodology includes an overview of Amazigh corpora. (Introduction)\n",
      "*   **Tagging Process with AnCoraPipe**: The paper describes the procedure for tagging using AnCoraPipe. (Introduction)\n",
      "*   **Amazigh Tagset Definition**: A dedicated section addresses the Amazigh tagset. (Introduction)\n",
      "*   **Writing System**: The Tifinaghe alphabet, standardized by IRCAM, is adopted as the official graphic system for writing Amazigh, consisting of 33 alphabetical phonetic entities. (The Amazigh language)\n",
      "\n",
      "**Results/Findings**:\n",
      "While the provided excerpt primarily details the problem, aims, and methodology, it underscores the critical need for NLP tools for Amazigh. The paper's immediate \"finding\" or outcome is the proposed framework and adaptation of AnCoraPipe to serve as a foundational morphosyntactic tagger. The broader impact is setting the stage for more advanced automatic processing of the Amazigh language, addressing its linguistic diversity and the recent standardization efforts by institutions like IRCAM. The document highlights the significant decrease in Amazigh speakers, reinforcing the urgency of such linguistic preservation and processing efforts. (Abstract, Introduction, The Amazigh language)\n",
      "Summarizer > This paper, \"Tagging Amazigh with AnCoraPipe,\" primarily focuses on introducing morphosyntactic tagging for the Amazigh language using the AnCora Pipe multilevel annotation tool. This is presented as an initial step towards automatic Amazigh language processing, aiming to develop a part-of-speech tagger.\n",
      "\n",
      "Key contributions include addressing the critical scarcity of NLP tools for Amazigh, adapting AnCora Pipe to incorporate a specific tagset designed for Amazigh corpora, and establishing a foundational framework for its automatic processing using a newly defined Tifinaghe writing system.\n",
      "\n",
      "The methodology involves providing an overview of Amazigh language features (Hamito-Semitic origins, rich templatic morphology, dialectal proliferation, IRCAM's Tifinaghe alphabet standardization), a retrospective on Amazigh morphology as conceptualized by IRCAM linguists, an overview of Amazigh corpora, and detailed descriptions of the AnCoraPipe tagging procedure and the Amazigh tagset definition.\n",
      "\n",
      "The paper's main outcome is the proposed framework and adaptation of AnCoraPipe to serve as a foundational morphosyntactic tagger for Amazigh. It sets the stage for more advanced automatic processing, acknowledging the language's linguistic diversity and the urgency of preservation efforts due to decreasing speaker numbers.\n",
      "Tech_Researcher > The paper \"Tagging Amazigh with AnCoraPipe\" addresses the significant scarcity of Natural Language Processing (NLP) tools and resources for the Amazigh language. Its main technical focus is to introduce morphosyntactic tagging for Amazigh by adapting the AnCora Pipe multilevel annotation tool. This endeavor aims to lay the groundwork for automatic processing of Amazigh, with the immediate objective of developing a part-of-speech tagger. The research problem is the critical lack of essential NLP infrastructure for a low-resource language like Amazigh.\n",
      "\n",
      "**Methodology**:\n",
      "The authors employ a structured approach:\n",
      "1.  **Language Features Overview**: They first detail Amazigh's Hamito-Semitic origins, rich templatic morphology, and extensive dialectal variations.\n",
      "2.  **Morphology Retrospective**: A review of Amazigh morphology, as defined by IRCAM linguists, is presented.\n",
      "3.  **Corpus Overview**: The paper includes an overview of existing Amazigh corpora.\n",
      "4.  **Tagging Process with AnCoraPipe**: The procedure for utilizing AnCora Pipe for tagging is described.\n",
      "5.  **Amazigh Tagset Definition**: A dedicated, specific tagset for Amazigh is defined.\n",
      "6.  **Writing System**: The IRCAM-standardized Tifinaghe alphabet, comprising 33 phonetic entities, is adopted as the official writing system for annotation.\n",
      "\n",
      "**Main Technical Focus**:\n",
      "The core technical contribution is the adaptation of the AnCora Pipe tool and the definition of a custom tagset and writing system to enable morphosyntactic tagging for Amazigh, a crucial initial step for any advanced NLP for the language.\n",
      "\n",
      "### Technical Evaluation:\n",
      "\n",
      "*   **Innovative**: The innovation lies in adapting an established multilingual annotation tool (AnCora Pipe) for a critically under-resourced language like Amazigh, which possesses complex templatic morphology and has recently standardized its Tifinaghe writing system. This initial framework addresses a fundamental gap in Amazigh NLP, offering a concrete step towards digital language preservation and processing.\n",
      "*   **Weak or Missing**: The paper, based on the abstract and introduction, primarily outlines a proposed framework rather than presenting concrete results or empirical evaluations of the AnCoraPipe adaptation. Specifics regarding the size and nature of the Amazigh corpora used for tagset development or testing are not detailed. The technical challenges encountered during the adaptation of AnCoraPipe to Amazigh's unique morphology and the performance metrics (e.g., accuracy, speed) of the tagging process are not provided in the excerpt. A thorough description of the \"specific tagset\" beyond its existence would also strengthen the technical contribution.\n",
      "*   **Assumptions**: The paper assumes that AnCora Pipe is sufficiently flexible and robust to be effectively adapted to the unique morphological characteristics of Amazigh. It also implicitly assumes that the IRCAM-conceptualized morphology and the newly defined Tifinaghe writing system are stable and suitable foundations for developing a tagset and computational tools.\n",
      "*   **Possible Real-world Applications**: This work lays the groundwork for various applications, including the development of robust part-of-speech taggers for Amazigh, improved search engines for Amazigh content, machine translation systems, educational tools for language learning, linguistic research, and the digital preservation and revitalization of the Amazigh language.\n",
      "\n",
      "### Latest Research & Synthesis:\n",
      "\n",
      "The original paper proposes a foundational approach to Amazigh morphosyntactic tagging using AnCoraPipe. Recent research (2024-2025) strongly validates this focus on low-resource languages. Multiple initiatives, like the Workshop on Language Models for Low-Resource Languages (LoResLM 2025), highlight the continued need for linguistic resources and specialized models, especially for languages with complex morphology and dialectal variation like Amazigh.\n",
      "\n",
      "While the paper lays the groundwork by defining a tagset and adapting AnCoraPipe, current trends emphasize leveraging advanced machine learning, deep learning, and transformer-based models for improved accuracy, often through transfer learning from high-resource languages or multilingual models like mBERT and XLM-R. Specifically for Amazigh, recent work has explored various machine learning algorithms for POS tagging, with Conditional Random Fields (CRF) showing promising results on a 60,000-token corpus. Some studies have achieved accuracies above 90% for Amazigh POS tagging using these methods on annotated corpora of around 60k-85k tokens with 28 tags.\n",
      "\n",
      "The original paper's methodology is sound for establishing initial resources. However, it implicitly assumes that a rule-based or hybrid approach with AnCoraPipe would be sufficiently performant. Current research suggests that while rule-based methods were foundational, statistical and neural approaches now dominate, offering superior accuracy for POS tagging and other NLP tasks.\n",
      "\n",
      "**Concise Synthesis (max 100 words):**\n",
      "The paper's adaptation of AnCoraPipe for Amazigh morphosyntactic tagging is innovative for a low-resource language with complex morphology. Weaknesses include a lack of empirical results or performance metrics for the proposed framework. Current NLP trends (2024-2025) strongly validate the paper's focus on low-resource languages, emphasizing advanced neural models and transfer learning over purely rule-based systems. Subsequent research has successfully applied various machine learning algorithms, notably CRF, achieving high accuracy (e.g., >90% on ~60k tokens) for Amazigh POS tagging, thus building directly on the foundational work the paper proposes. Missing gaps include detailed performance analysis and integration with large language models.\n",
      "ResearchAggregator > ## Research Report: Tagging Amazigh with AnCoraPipe\n",
      "\n",
      "This report synthesizes the key findings, methodology, and technical evaluation of the paper \"Tagging Amazigh with AnCoraPipe,\" contextualizing it within the landscape of recent Natural Language Processing (NLP) research for low-resource languages.\n",
      "\n",
      "### 1. Introduction and Main Purpose\n",
      "\n",
      "The paper addresses the critical scarcity of NLP tools and resources for the Amazigh language, a low-resource language with rich templatic morphology and significant dialectal variation. Its primary objective is to introduce morphosyntactic tagging for Amazigh by adapting the AnCora Pipe multilevel annotation tool. This effort is presented as a foundational step towards automatic Amazigh language processing, with the immediate goal of developing a robust part-of-speech (POS) tagger. The broader aim is to support digital language preservation and revitalization efforts, especially given the decreasing numbers of Amazigh speakers.\n",
      "\n",
      "### 2. Methodology\n",
      "\n",
      "The authors employ a structured approach to adapt AnCora Pipe for Amazigh:\n",
      "\n",
      "1.  **Language Features Overview**: The paper begins by detailing Amazigh's Hamito-Semitic origins, its complex templatic morphology, and the extensive proliferation of its dialects across North Africa. It also notes the standardization efforts by institutions like IRCAM.\n",
      "2.  **Morphology Retrospective**: A review of Amazigh morphology, as conceptualized and documented by IRCAM linguists, provides the linguistic basis for the tagging system.\n",
      "3.  **Corpus Overview**: An overview of existing Amazigh corpora is included, likely serving as potential data sources for annotation and development.\n",
      "4.  **AnCoraPipe Tagging Procedure**: The paper describes the specific procedure for utilizing the AnCora Pipe tool for morphosyntactic annotation.\n",
      "5.  **Amazigh Tagset Definition**: A dedicated and specific tagset is defined for Amazigh, tailored to its unique linguistic characteristics.\n",
      "6.  **Writing System**: The IRCAM-standardized Tifinaghe alphabet, comprising 33 phonetic entities, is adopted as the official writing system for annotation.\n",
      "\n",
      "The core technical contribution lies in this adaptation of AnCora Pipe and the definition of a custom tagset and writing system, which collectively enable the crucial initial step of morphosyntactic tagging for Amazigh.\n",
      "\n",
      "### 3. Key Contributions and Findings\n",
      "\n",
      "The paper's main outcome is the proposed framework and the successful adaptation of AnCoraPipe to function as a foundational morphosyntactic tagger for Amazigh. This establishes a crucial initial infrastructure for a critically under-resourced language. By addressing the lack of NLP tools, defining a language-specific tagset, and integrating it with a standardized writing system (Tifinaghe), the work sets the stage for more advanced automatic processing. It acknowledges the urgency of language preservation due to declining speaker numbers and the inherent linguistic diversity of Amazigh.\n",
      "\n",
      "### 4. Technical Evaluation\n",
      "\n",
      "*   **Innovative Aspects**: The innovation lies in applying an established multilingual annotation tool (AnCora Pipe) to a critically under-resourced language like Amazigh, which presents unique challenges due to its complex templatic morphology and recently standardized Tifinaghe writing system. This framework represents a concrete and foundational step towards digital language preservation and processing.\n",
      "*   **Weaknesses and Missing Information**: The paper primarily outlines a proposed framework rather than presenting concrete empirical results or evaluations of the AnCoraPipe adaptation. Key specifics regarding the size and nature of the Amazigh corpora used for tagset development or testing are not detailed. Furthermore, the technical challenges encountered during the adaptation process, the performance metrics (e.g., accuracy, speed) of the tagging, and a thorough description of the \"specific tagset\" itself are not provided in the available excerpts.\n",
      "*   **Assumptions**: The paper implicitly assumes that AnCora Pipe is sufficiently flexible to effectively handle Amazigh's unique morphological characteristics. It also assumes that the IRCAM-conceptualized morphology and the standardized Tifinaghe writing system are stable and suitable foundations for developing computational tools and a tagset.\n",
      "*   **Possible Real-world Applications**: This foundational work has significant potential, paving the way for applications such as robust part-of-speech taggers, improved search engines for Amazigh content, machine translation systems, educational tools for language learning, advanced linguistic research, and the broader digital preservation and revitalization of the Amazigh language.\n",
      "\n",
      "### 5. Latest Research & Synthesis\n",
      "\n",
      "The original paper's focus on creating foundational NLP resources for Amazigh is strongly validated by recent research (2024-2025). Initiatives like the Workshop on Language Models for Low-Resource Languages (LoResLM 2025) underscore the ongoing need for linguistic resources and specialized models, particularly for languages with complex morphology and dialectal variation.\n",
      "\n",
      "While the paper proposes a sound methodology for establishing initial resources using AnCoraPipe, it implicitly suggests a rule-based or hybrid approach. Current NLP trends, however, heavily emphasize leveraging advanced machine learning, deep learning, and transformer-based models for superior accuracy. These modern approaches often utilize transfer learning from high-resource languages or multilingual models like mBERT and XLM-R.\n",
      "\n",
      "Subsequent research for Amazigh POS tagging has successfully applied various machine learning algorithms, notably Conditional Random Fields (CRF), achieving promising results. Studies have reported accuracies above 90% for Amazigh POS tagging on annotated corpora ranging from approximately 60,000 to 85,000 tokens using 28 tags. This demonstrates that while the AnCoraPipe framework is a vital initial step, advanced statistical and neural methods offer significantly higher performance for the actual tagging task.\n",
      "\n",
      "**Missing Gaps in Original Work (in light of current trends):** The original paper's primary gaps are the lack of detailed performance analysis of the AnCoraPipe adaptation and the absence of exploration into integrating the proposed framework with advanced machine learning algorithms or large language models, which are now standard for achieving high accuracy in NLP tasks.\n",
      "\n",
      "### 6. Conclusion\n",
      "\n",
      "\"Tagging Amazigh with AnCoraPipe\" presents an innovative and crucial first step towards providing essential NLP infrastructure for the low-resource Amazigh language. By adapting an existing annotation tool and defining a custom tagset within a standardized writing system, it lays the groundwork for future automatic processing. While the paper's methodology is foundational and well-conceived, its primary weakness lies in the absence of empirical evaluation. Latest research confirms the importance of such foundational work for low-resource languages but also highlights the significant advancements in statistical and neural approaches, which have since achieved high accuracies for Amazigh POS tagging, building directly on the kind of resource development proposed in this paper.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=agents)\n",
    "response = await runner.run_debug(\n",
    "    \"Analyse document.pdf the document and provide a comprehensive summary of the key findings and methodology.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
