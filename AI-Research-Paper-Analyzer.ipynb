{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6eb1b1",
   "metadata": {},
   "source": [
    "# ü§ñ Automated Research Paper Analysis System\n",
    "**Multi-Agent AI System for Academic Research Analysis**\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Mohamed Outahajala  \n",
    " \n",
    "**Framework**: Google Agent Development Kit (ADK)  \n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Upload your PDF research paper as `document.pdf`\n",
    "2. Set your API keys in `.env`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d0fc0",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Analyzing research papers manually is time-consuming and requires:\n",
    "- Reading lengthy PDFs\n",
    "- Summarizing key findings\n",
    "- Researching latest trends\n",
    "- Synthesizing information from multiple sources\n",
    "\n",
    "This process can take 2-3 hours per paper.\n",
    "\n",
    "## Solution\n",
    "An automated Multi-Agent Research System that:\n",
    "- Extracts PDF content automatically\n",
    "- Generates comprehensive summaries\n",
    "- Performs real-time market research\n",
    "- Produces structured reports in under 5 minutes\n",
    "\n",
    "**Value**: Reduces research time by 95%, from 3 hours to 5 minutes per paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ca3ea",
   "metadata": {},
   "source": [
    "<!-- if numpy or pandas .. not installed -->\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install pypdf\n",
    "!pip install google-adk\n",
    "!pip install nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eea3986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_SEARCH_API_KEY = os.getenv(\"GOOGLE_SEARCH_API_KEY\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gemini-2.5-flash\")  # Default to \"gemini-2.5-flash\" if not set   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e264923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75aac47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config=types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fc24a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a9e4b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/admin/HF/Agents5D\n",
      "Files in current directory:\n",
      "  üìÑ document.pdf\n",
      "‚úÖ 'document.pdf' found and accessible\n",
      "   Pages: 5\n",
      "   First 100 chars: Tagging Amazigh with AnCoraPipe \n",
      "Mohamed Outahajala, Lahbib Zekouar, Paolo Rosso, M. Ant√≤nia Mart√≠ \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check if document.pdf is accessible\n",
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in current directory:\")\n",
    "for item in os.listdir('.'):\n",
    "    if item.endswith('.pdf'):\n",
    "        print(f\"  üìÑ {item}\")\n",
    "\n",
    "# Check if document.pdf exists\n",
    "pdf_path = \"document.pdf\"\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"‚úÖ '{pdf_path}' found and accessible\")\n",
    "    # Quick test read\n",
    "    from pypdf import PdfReader\n",
    "    reader = PdfReader(pdf_path)\n",
    "    print(f\"   Pages: {len(reader.pages)}\")\n",
    "    print(f\"   First 100 chars: {reader.pages[0].extract_text()[:100]}...\")\n",
    "else:\n",
    "    print(f\"‚ùå '{pdf_path}' NOT found in current directory\")\n",
    "    print(f\"   You may need to specify the full path or move the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56e26a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF Search Tool initialized.\n",
      "‚úÖ PDF Reader Agent created.\n"
     ]
    }
   ],
   "source": [
    "# PDF Search Tool\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def search_pdf_tool(file_path: str, query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for keywords within a PDF file and returns relevant text snippets.\n",
    "    If the file is not found, returns mock data for demonstration.\n",
    "    \"\"\"\n",
    "    print(f\"    üîé [Tool] Searching PDF '{file_path}' for: '{query}'\")\n",
    "    \n",
    "    # 1. Try to read the actual file\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            reader = PdfReader(file_path)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "            \n",
    "            # Return full document text instead of keyword matching\n",
    "            if text.strip():\n",
    "                return text[:5000]  # Return first 5000 chars to avoid token limits\n",
    "            else:\n",
    "                return \"PDF file is empty or unreadable.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error reading PDF: {e}\"\n",
    "\n",
    "    # 2. Fallback Mock Data (for testing without a file)\n",
    "    else:\n",
    "        print(f\"    ‚ö†Ô∏è [Tool] File not found. Using MOCK data for demonstration.\")\n",
    "        mock_content = \"\"\"\n",
    "Research Paper: Advanced AI Systems\n",
    "\n",
    "Abstract: This paper presents a novel framework for multi-agent AI systems that can collaborate to solve complex research problems.\n",
    "\n",
    "Introduction: The field of artificial intelligence has rapidly evolved with the emergence of large language models and agent-based architectures.\n",
    "\n",
    "Methodology: We employed a sequential workflow combining PDF analysis, parallel processing, and result aggregation using the Google ADK framework.\n",
    "\n",
    "Key Findings:\n",
    "- Multi-agent systems show 95% improvement in research analysis speed\n",
    "- Parallel execution reduces processing time by 60%\n",
    "- Integration with real-time search enables up-to-date information retrieval\n",
    "\n",
    "Conclusion: Our approach demonstrates significant improvements in automating research paper analysis.\n",
    "        \"\"\"\n",
    "        return mock_content\n",
    "\n",
    "print(\"‚úÖ PDF Search Tool initialized.\")\n",
    "\n",
    "# 1. PDF Reader Agent - FIXED\n",
    "pdf_reader_agent = Agent(\n",
    "    name=\"PDFReader\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an expert document researcher. \n",
    "    \n",
    "    The user will specify which PDF file to analyze in their message.\n",
    "    Use the search_pdf_tool to extract content from that PDF file.\n",
    "    \n",
    "    Analyze the document and provide a structured analysis with these sections:\n",
    "    \n",
    "    **Main Topic**: [Brief description of what the paper is about]\n",
    "    \n",
    "    **Key Contributions**: [List the novel contributions and innovations]\n",
    "    \n",
    "    **Methodology**: [Describe the approaches and methods used]\n",
    "    \n",
    "    **Results/Findings**: [Summarize the main outcomes and conclusions]\n",
    "    \n",
    "    Keep your response clear and structured. Cite specific sections when relevant.\n",
    "    Do not return the raw text - provide your analysis.\"\"\",\n",
    "    tools=[FunctionTool(search_pdf_tool)],\n",
    "    output_key=\"pdf_findings\"\n",
    ")\n",
    "print(\"‚úÖ PDF Reader Agent created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "070ee52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Summarizer Agent\n",
    "summarizer_agent = Agent(\n",
    "    name=\"Summarizer\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"You are an expert scientific paper analyst. \n",
    "    Read the research paper content provided: {pdf_findings}\n",
    "    \n",
    "    Create a comprehensive summary that includes:\n",
    "    1. **Main Topic**: What is the paper about?\n",
    "    2. **Key Contributions**: What are the novel contributions and innovations?\n",
    "    3. **Methodology**: What approaches or methods were used?\n",
    "    4. **Results/Findings**: What were the main outcomes?\n",
    "    \n",
    "    Keep the summary clear, structured, and under 200 words.\n",
    "    If the findings are empty, state that no information was found.\"\"\",\n",
    "    output_key=\"final_summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b288e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tech Researcher\n",
    "tech_researcher = Agent(\n",
    "    name=\"Tech_Researcher\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "\n",
    "    instruction=\"\"\"\n",
    "You are a senior research analyst.\n",
    "\n",
    "Input: {pdf_findings}\n",
    "\n",
    "1. Extract the paper‚Äôs **main technical focus**, research problem, and method.\n",
    "2. Evaluate the paper technically:\n",
    "   - What is innovative?\n",
    "   - What is weak or missing?\n",
    "   - What assumptions does it make?\n",
    "   - Possible real-world applications?\n",
    "3. Perform a web search using the search tool:\n",
    "   - Find the latest (2024‚Äì2025) work, breakthroughs, or criticisms related to the same topic.\n",
    "   - Prefer scholarly or technical sources.\n",
    "4. Produce a concise synthesis (max 100 words):\n",
    "   - Technical evaluation of the paper\n",
    "   - How the latest research trends compare or validate/challenge it\n",
    "   - Missing gaps or future directions\n",
    "\n",
    "Your output must be factual, technical, and short.\n",
    "\"\"\",\n",
    "\n",
    "    tools=[google_search],\n",
    "    output_key=\"tech_research\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7de234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic_reviewer = Agent(\n",
    "    name=\"LinguisticReviewer\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "You are a senior linguist specializing in Afro-Asiatic languages, morphology, and computational tagging.\n",
    "\n",
    "Input:\n",
    "{pdf_findings}\n",
    "\n",
    "Your task:\n",
    "Provide a rigorous linguistic analysis of the paper, focusing on:\n",
    "- correctness of linguistic claims\n",
    "- completeness and adequacy of the tagset\n",
    "- treatment of Amazigh morphology (root‚Äìpattern, affixes, clitics)\n",
    "- dialectal consistency and variation issues\n",
    "- writing system adequacy (Tifinaghe, Arabic script, Latin script)\n",
    "- grammatical phenomena that should be included but are missing\n",
    "- potential linguistic ambiguities or tagging challenges\n",
    "\n",
    "Output:\n",
    "Produce an actionable review section titled ‚ÄúLinguistic Analysis & Recommendations‚Äù.\n",
    "Be technical, precise, and non-redundant.\n",
    "\"\"\",\n",
    "    output_key=\"linguistic_review\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adf11987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ParallelAgent runs all its sub-agents simultaneously\n",
    "# other agents can be added here later\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"ParallelResearchTeam\",\n",
    "    sub_agents=[summarizer_agent, tech_researcher, linguistic_reviewer],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f1cc92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_aggregator = Agent(\n",
    "    name=\"ResearchAggregator\",\n",
    "    model=Gemini(model=MODEL_NAME, api_key=GOOGLE_API_KEY, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "You are a Senior Research Reviewer providing a CONCISE expert review with scores.\n",
    "\n",
    "Inputs:\n",
    "1. Summary: {final_summary}\n",
    "2. Technical Analysis: {tech_research}\n",
    "3. Linguistic Analysis: {linguistic_review}\n",
    "\n",
    "Produce a professional peer review following this EXACT structure and format:\n",
    "\n",
    "---\n",
    "\n",
    "## Scores\n",
    "**Knowledge of the Field:** [1-5]/5\n",
    "**Soundness:** [1-5]5\n",
    "**Clarity:** [1-5]/5\n",
    "**Originality of the Approach:** [1-5]/5\n",
    "**Significance of Results:** [1-5]/5\n",
    "**Replicability:** [1-5]/5\n",
    "\n",
    "**Overall Assessment:** [1-5]/5\n",
    "\n",
    "**Decision:** [Reject/Weak Reject/Borderline/Accept/Strong Accept]\n",
    "\n",
    "*Scoring Guide:*\n",
    "- 1 = Should be rejected without doubt\n",
    "- 2 = Some salvageable ideas, but reject\n",
    "- 3 = Ambivalent, OK to accept but not enthusiastic\n",
    "- 4 = Should be accepted\n",
    "- 5 = Enthusiastically advocate for acceptance\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary (3-4 sentences)\n",
    "One paragraph overview of paper's purpose and significance.\n",
    "\n",
    "## Key Contributions (3-5 bullet points)\n",
    "‚Ä¢ Most important contribution\n",
    "‚Ä¢ Second contribution\n",
    "‚Ä¢ Third contribution\n",
    "\n",
    "## Methodology (2-3 sentences)\n",
    "Brief description of approach used.\n",
    "\n",
    "## Critical Assessment\n",
    "\n",
    "**Strengths:**\n",
    "- Strength 1\n",
    "- Strength 2\n",
    "\n",
    "**Weaknesses:**\n",
    "- Weakness 1\n",
    "- Weakness 2\n",
    "- Missing element or gap\n",
    "\n",
    "## Linguistic Review (2-3 sentences)\n",
    "Brief comment on linguistic adequacy, tagset, and morphology handling.\n",
    "\n",
    "## Recommendations (4-5 points)\n",
    "1. Most critical improvement\n",
    "2. Second priority\n",
    "3. Third priority\n",
    "4. Additional suggestion\n",
    "\n",
    "---\n",
    "\n",
    "CRITICAL RULES:\n",
    "- Provide honest, justified scores based on the analysis\n",
    "- Be consistent between scores and written assessment\n",
    "- TOTAL LENGTH: 300-450 words maximum\n",
    "- Be direct and specific\n",
    "- Professional reviewer tone\n",
    "- Cite specific issues with evidence\n",
    "- Prioritize actionable feedback\n",
    "\"\"\",\n",
    "    output_key=\"research_report\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67ee5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential Agent to agregate read PDF, then run workflow\n",
    "agents = SequentialAgent(\n",
    "    name=\"ResearchWorkflowAgent\",\n",
    "    sub_agents=[pdf_reader_agent, parallel_research_team, research_aggregator],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f98ae92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_file can be changed to analyze different documents\n",
    "# the file could be in /Users/admin/Downloads for example\n",
    "string_pdf_file = \"document.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Multi-Agent Analysis...\n",
      "üìÑ Analyzing: document.pdf\n",
      "================================================================================\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Analyse document.pdf and provide a comprehensive summary of the key findings and methodology.\n",
      "    üîé [Tool] Searching PDF 'document.pdf' for: 'introduction OR abstract OR methodology OR methods OR results OR findings OR conclusion OR summary OR contributions'\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from google.genai.types import Content, Part\n",
    "import asyncio\n",
    "\n",
    "runner = InMemoryRunner(agent=agents, app_name=\"agents\")\n",
    "\n",
    "async def run_analysis_async(pdf_file=string_pdf_file):\n",
    "    \"\"\"Async function to run the analysis using run_debug\"\"\"\n",
    "    try:\n",
    "        print(\"üöÄ Starting Multi-Agent Analysis...\")\n",
    "        print(f\"üìÑ Analyzing: {pdf_file}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Use run_debug - the filename is in the message\n",
    "        result = await runner.run_debug(\n",
    "            f\"Analyse {pdf_file} and provide a comprehensive summary of the key findings and methodology.\"\n",
    "        )\n",
    "        \n",
    "        # Extract text from result\n",
    "        final_text = None\n",
    "        if result:\n",
    "            # Check if result is a string\n",
    "            if isinstance(result, str):\n",
    "                final_text = result\n",
    "            # Check if it has a text attribute\n",
    "            elif hasattr(result, 'text'):\n",
    "                final_text = result.text\n",
    "            # Check if it's a Content object with parts\n",
    "            elif hasattr(result, 'parts') and result.parts:\n",
    "                final_text = result.parts[0].text\n",
    "            # Try to convert to string\n",
    "            else:\n",
    "                final_text = str(result)\n",
    "        \n",
    "        # Print the result\n",
    "        print(\"=\" * 80)\n",
    "        if final_text:\n",
    "            #print(\"üìä FINAL RESEARCH REPORT\")\n",
    "            #print(\"=\" * 80)\n",
    "            #print(final_text)\n",
    "            print(\"=\" * 80)\n",
    "            #print(\"‚úÖ Analysis Complete!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No response received\")\n",
    "            print(f\"Debug - Result type: {type(result)}\")\n",
    "            print(f\"Debug - Result: {result}\")\n",
    "        \n",
    "        return final_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Change the pdf_file parameter to analyze different PDFs\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    # We're in a running loop (Jupyter), use nest_asyncio\n",
    "    result = await run_analysis_async(pdf_file=string_pdf_file)  # Change filename here\n",
    "except RuntimeError:\n",
    "    # No running loop, create one\n",
    "    result = asyncio.run(run_analysis_async(pdf_file=string_pdf_file))  # Change filename here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
